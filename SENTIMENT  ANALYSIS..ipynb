{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a950d9f",
   "metadata": {},
   "source": [
    "##   SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a705c07b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c16e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "We will be doing a sentimnent analysis where we will be also deploying and using our model using gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e330a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5647a6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv('samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f045ef90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d9540e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>why does google criminalize asian women by gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>watching the streamers tear the bags build the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>mfs be 17 in the training facilities of fifa b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>inm watching reviews of the old assassins cree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>narendramodi  pmoindia please help me twitter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0  Negative  why does google criminalize asian women by gen...\n",
       "1  Positive  watching the streamers tear the bags build the...\n",
       "2  Negative  mfs be 17 in the training facilities of fifa b...\n",
       "3  Negative  inm watching reviews of the old assassins cree...\n",
       "4  Negative   narendramodi  pmoindia please help me twitter..."
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4b771b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.sentiment != \"Irrelevant\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4e3a68",
   "metadata": {},
   "source": [
    "For the data that we will need to process there should not be null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8b531c93",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "text         3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "60f69b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dc03cf",
   "metadata": {},
   "source": [
    "In the below code we will be encoding our data and dataset where we will map our positive values to 1 and our negative values to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "eb62ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['sentiment'].isin(['Positive', 'Negative'])]\n",
    "df['sentiment'] = df['sentiment'].map({'Positive': 1, 'Negative': 0})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1ad63ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "unique_sentiments = df['sentiment'].unique()\n",
    "print(unique_sentiments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384fc3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4dd4ecfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>why does google criminalize asian women by gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>watching the streamers tear the bags build the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>mfs be 17 in the training facilities of fifa b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>inm watching reviews of the old assassins cree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>narendramodi  pmoindia please help me twitter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  why does google criminalize asian women by gen...\n",
       "1          1  watching the streamers tear the bags build the...\n",
       "2          0  mfs be 17 in the training facilities of fifa b...\n",
       "3          0  inm watching reviews of the old assassins cree...\n",
       "4          0   narendramodi  pmoindia please help me twitter..."
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a6c963",
   "metadata": {},
   "source": [
    "When executing the below code we are  turning the text from uppercase to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6cdc85d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbbad40",
   "metadata": {},
   "source": [
    "In the below code we will be looking at the distrbution of our target features and we can see that our target variable is close to balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c5c417df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1693\n",
       "1    1399\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ee6819",
   "metadata": {},
   "source": [
    "For this below line of code we are splitting our dataset to our training and test data  for training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9e419a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['sentiment'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f3aa69a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data points: 2473\n",
      "Number of train labels: 2473\n",
      "Number od test data points: 619\n",
      "Number of test labels: 619\n"
     ]
    }
   ],
   "source": [
    "print('Number of train data points:',len(X_train))\n",
    "print('Number of train labels:',len(y_train))\n",
    "print('Number od test data points:',len(X_test))\n",
    "print('Number of test labels:',len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d6a29a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformersNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "     ---------------------------------------- 7.2/7.2 MB 71.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from transformers) (1.19.5)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.3.1-cp39-cp39-win_amd64.whl (263 kB)\n",
      "     ------------------------------------ 263.9/263.9 kB 463.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-win_amd64.whl (3.5 MB)\n",
      "     ---------------------------------------- 3.5/3.5 MB 190.4 kB/s eta 0:00:00\n",
      "Collecting huggingface-hub<1.0,>=0.14.1\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "     ------------------------------------ 268.8/268.8 kB 147.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2022.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8a42eb",
   "metadata": {},
   "source": [
    "In the below codethe DistilBertTokenizerFast class is imported from the transformers library. Then, the tokenizer instance is created using the from_pretrained method, specifying the pre-trained model distilbert-base-uncased-finetuned-sst-2-english. This tokenizer can be used to tokenize and preprocess text for tasks such as sentiment analysis or text classification using the DistilBERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a1a46c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  transformers  import DistilBertTokenizerFast\n",
    "models ='distilbert-base-uncased-finetuned-sst-2-english'\n",
    "tokenizer =DistilBertTokenizerFast.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "46cc48f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: chile verizon said fuck the\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 9), dtype=int32, numpy=array([[  101,  7029,  2310, 21885,  2239,  2056,  6616,  1996,   102]])>, 'attention_mask': <tf.Tensor: shape=(1, 9), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1]])>}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('text:', X_train.iloc[0])\n",
    "tokenizer(X_train.iloc[0], truncation=True, padding=True, max_length=256, return_tensors=\"tf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3b2269f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205                           chile verizon said fuck the\n",
      "3339    i dont know what im doing wrong but the rogue ...\n",
      "3987    7 took a little over a full month and to get e...\n",
      "2507    i  m already beginning to get think that this ...\n",
      "3582                        impo ant research and so much\n",
      "                              ...                        \n",
      "2095                 psas clean paladin is still terrible\n",
      "1394    why the fuck is nobody playing rush on battlef...\n",
      "1438                       after taking a few games nba2k\n",
      "1640                     cuz i love pubg more than my bae\n",
      "1107    bruh the sony reveal was pointless did we get ...\n",
      "Name: text, Length: 2473, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a857c0",
   "metadata": {},
   "source": [
    "The code below is using the `tokenizer` object to encode and preprocess text data using the Hugging Face `transformers` library. It assumes that you have defined the `tokenizer` object and set the `MAX_LENGTH` variable to 256. \n",
    "\n",
    "The code then applies the tokenizer to the training and test data (`X_train` and `X_test`). It performs the following steps:\n",
    "\n",
    "\n",
    "- `tokenizer`: Calls the tokenizer object.\n",
    "- `X_train.tolist()`: Converts the training data to a list if it's not already in list format.\n",
    "- `truncation=True`: Truncates the input sequences to the specified `MAX_LENGTH` if they exceed it.\n",
    "- `padding=True`: Adds padding to the sequences to ensure they have the same length.\n",
    "- `return_tensors=\"tf\"`: Returns TensorFlow tensors as the output format.\n",
    "- `max_length=MAX_LENGTH`: Specifies the maximum length of the tokenized sequences.\n",
    "\n",
    "The steps for encoding the test data are the same as for the training data, but it applies the tokenizer to the `X_test` data.\n",
    "\n",
    "After running this code, `train_encodings` and `test_encodings` will contain the encoded and preprocessed representations of the training and test data, respectively, suitable for input to a downstream machine learning model, such as a BERT-based classifier or sequence labeling model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1cef9167",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 256\n",
    "\n",
    "train_encodings = tokenizer(\n",
    "    X_train.tolist(),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors=\"tf\",\n",
    "    max_length=MAX_LENGTH\n",
    ")\n",
    "\n",
    "test_encodings = tokenizer(\n",
    "    X_test.tolist(),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors=\"tf\",\n",
    "    max_length=MAX_LENGTH\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f921b586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d1bd5799",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train =tf.data.Dataset.from_tensor_slices((dict(train_encodings),\n",
    "                                         y_train))\n",
    "test =tf.data.Dataset.from_tensor_slices((dict(test_encodings),\n",
    "                                       y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "26c2d57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5336e56f237046dfb671a2bf9b83dad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFDistilBertForSequenceClassification\n",
    "\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=models,\n",
    "    num_labels=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fb678f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=5e-5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "06e3612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss_func, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "435d7af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "distilbert (TFDistilBertMain multiple                  66362880  \n",
      "_________________________________________________________________\n",
      "pre_classifier (Dense)       multiple                  590592    \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  1538      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         multiple                  0         \n",
      "=================================================================\n",
      "Total params: 66,955,010\n",
      "Trainable params: 66,955,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fc867e",
   "metadata": {},
   "source": [
    "In the below line of code we have two epochs where we have a validation acucuracy of 80 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e8b592be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "155/155 [==============================] - 1639s 11s/step - loss: 0.3781 - accuracy: 0.8439 - val_loss: 0.4262 - val_accuracy: 0.8061\n",
      "Epoch 2/2\n",
      "155/155 [==============================] - 1492s 10s/step - loss: 0.1913 - accuracy: 0.9232 - val_loss: 0.4605 - val_accuracy: 0.8094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23e80829190>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE =16\n",
    "NUM_EPOCHS =2\n",
    "model.fit(train.shuffle(len(X_train)).batch(BATCH_SIZE),\n",
    "         epochs =NUM_EPOCHS,\n",
    "         batch_size=BATCH_SIZE,\n",
    "         validation_data=test.shuffle(len(X_test)).batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "800b4dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('/sentiment_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b8766884",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_data=df.sample(frac=0.05,random_state =42)\n",
    "unseen_reviews =unseen_data['text'].tolist()\n",
    "unseen_encodings =tokenizer(unseen_reviews,\n",
    "                           padding=True,\n",
    "                           truncation=True,\n",
    "                           max_length =MAX_LENGTH,\n",
    "                           return_tensors =\"tf\")\n",
    "y_unseen =unseen_data['sentiment'].tolist()\n",
    "unseen_encodings=tf.data.Dataset.from_tensor_slices((dict(unseen_encodings),\n",
    "                                                   y_unseen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2d88209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'positive': 1, 'negative': 0}\n",
    "\n",
    "# Convert string labels to numeric values with a default value of -1 if label is not found\n",
    "y_train = [label_mapping.get(label, -1) for label in y_train]\n",
    "y_test = [label_mapping.get(label, -1) for label in y_test]\n",
    "\n",
    "# Filter out the examples with unknown labels\n",
    "y_train = [label for label in y_train if label != -1]\n",
    "y_test = [label for label in y_test if label != -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "8ac58e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "label_mapping = {\"label1\": 0, \"label2\": 1, \"label3\": 2}\n",
    "default_label = -1\n",
    "\n",
    "# Convert string labels to integers\n",
    "y_unseen = [label_mapping.get(label, default_label) for label in y_unseen]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd86081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e82a9c5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 24s 2s/step - loss: 0.4284 - accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.4284231960773468, 'accuracy': 0.800000011920929}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(unseen_encodings.shuffle(len(unseen_reviews)).batch(BATCH_SIZE),\n",
    "               return_dict=True,\n",
    "               batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "db9ac905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement gardio (from versions: none)\n",
      "ERROR: No matching distribution found for gardio\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install gardio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "36d46210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-3.36.1-py3-none-any.whl (19.8 MB)\n",
      "     ---------------------------------------- 19.8/19.8 MB 2.1 MB/s eta 0:00:00\n",
      "Collecting gradio-client>=0.2.7\n",
      "  Downloading gradio_client-0.2.9-py3-none-any.whl (288 kB)\n",
      "     -------------------------------------- 288.8/288.8 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting altair>=4.2.0\n",
      "  Downloading altair-5.0.1-py3-none-any.whl (471 kB)\n",
      "     -------------------------------------- 471.5/471.5 kB 2.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from gradio) (9.2.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from gradio) (2.11.3)\n",
      "Requirement already satisfied: markupsafe in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from gradio) (2.0.1)\n",
      "Collecting httpx\n",
      "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
      "     ---------------------------------------- 75.4/75.4 kB 4.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: matplotlib in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from gradio) (3.5.2)\n",
      "Collecting semantic-version\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting ffmpy\n",
      "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pandas in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from gradio) (1.4.4)\n",
      "Collecting markdown-it-py[linkify]>=2.0.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "     ---------------------------------------- 87.5/87.5 kB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from gradio) (2.28.1)\n",
      "Collecting python-multipart\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 45.7/45.7 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting orjson\n",
      "  Downloading orjson-3.9.2-cp39-none-win_amd64.whl (195 kB)\n",
      "     -------------------------------------- 195.5/195.5 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting pygments>=2.12.0\n",
      "  Downloading Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 1.1 MB/s eta 0:00:00\n",
      "Collecting aiofiles\n",
      "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from gradio) (0.22.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from gradio) (1.19.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.0 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from gradio) (0.16.4)\n",
      "Collecting mdit-py-plugins<=0.3.3\n",
      "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
      "     ---------------------------------------- 50.5/50.5 kB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from gradio) (1.10.9)\n",
      "Requirement already satisfied: fastapi in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from gradio) (0.97.0)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp39-cp39-win_amd64.whl (323 kB)\n",
      "     -------------------------------------- 323.6/323.6 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting websockets>=10.0\n",
      "  Downloading websockets-11.0.3-cp39-cp39-win_amd64.whl (124 kB)\n",
      "     -------------------------------------- 124.7/124.7 kB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: toolz in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from altair>=4.2.0->gradio) (0.11.2)\n",
      "Collecting typing-extensions>=4.0.1\n",
      "  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from altair>=4.2.0->gradio) (4.16.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from gradio-client>=0.2.7->gradio) (21.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from gradio-client>=0.2.7->gradio) (2022.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (3.6.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (4.64.1)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting linkify-it-py<3,>=1\n",
      "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
      "Collecting mdit-py-plugins<=0.3.3\n",
      "  Downloading mdit_py_plugins-0.3.2-py3-none-any.whl (50 kB)\n",
      "     -------------------------------------- 50.4/50.4 kB 855.1 kB/s eta 0:00:00\n",
      "  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl (46 kB)\n",
      "     ---------------------------------------- 46.5/46.5 kB 1.2 MB/s eta 0:00:00\n",
      "  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\n",
      "     ---------------------------------------- 43.7/43.7 kB ? eta 0:00:00\n",
      "  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl (41 kB)\n",
      "     -------------------------------------- 41.0/41.0 kB 992.5 kB/s eta 0:00:00\n",
      "  Downloading mdit_py_plugins-0.2.7-py3-none-any.whl (41 kB)\n",
      "     -------------------------------------- 41.0/41.0 kB 992.6 kB/s eta 0:00:00\n",
      "  Downloading mdit_py_plugins-0.2.6-py3-none-any.whl (39 kB)\n",
      "  Downloading mdit_py_plugins-0.2.5-py3-none-any.whl (39 kB)\n",
      "  Downloading mdit_py_plugins-0.2.4-py3-none-any.whl (39 kB)\n",
      "  Downloading mdit_py_plugins-0.2.3-py3-none-any.whl (39 kB)\n",
      "  Downloading mdit_py_plugins-0.2.2-py3-none-any.whl (39 kB)\n",
      "  Downloading mdit_py_plugins-0.2.1-py3-none-any.whl (38 kB)\n",
      "  Downloading mdit_py_plugins-0.2.0-py3-none-any.whl (38 kB)\n",
      "  Downloading mdit_py_plugins-0.1.0-py3-none-any.whl (37 kB)\n",
      "INFO: pip is looking at multiple versions of markdown-it-py[linkify] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting markdown-it-py[linkify]>=2.0.0\n",
      "  Using cached markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from pandas->gradio) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from pandas->gradio) (2.8.2)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (8.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from aiohttp->gradio) (2.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from aiohttp->gradio) (21.4.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp39-cp39-win_amd64.whl (61 kB)\n",
      "     ---------------------------------------- 61.7/61.7 kB 1.7 MB/s eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.0-cp39-cp39-win_amd64.whl (44 kB)\n",
      "     ---------------------------------------- 44.7/44.7 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from fastapi->gradio) (0.27.0)\n",
      "Requirement already satisfied: idna in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from httpx->gradio) (3.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from httpx->gradio) (2022.9.14)\n",
      "Requirement already satisfied: sniffio in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from httpx->gradio) (1.2.0)\n",
      "Collecting httpcore<0.18.0,>=0.15.0\n",
      "  Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
      "     ---------------------------------------- 74.5/74.5 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from matplotlib->gradio) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from matplotlib->gradio) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from matplotlib->gradio) (1.4.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from requests->gradio) (1.26.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from click>=7.0->uvicorn>=0.14.0->gradio) (0.4.5)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.5.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.18.0)\n",
      "Collecting uc-micro-py\n",
      "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.15.0)\n",
      "Building wheels for collected packages: ffmpy\n",
      "  Building wheel for ffmpy (setup.py): started\n",
      "  Building wheel for ffmpy (setup.py): finished with status 'done'\n",
      "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4693 sha256=93d5c7e2b5e38f21984361670db64563763706a8b5452cc89a643fd221a405d1\n",
      "  Stored in directory: c:\\users\\stilinski\\appdata\\local\\pip\\cache\\wheels\\91\\e2\\96\\f676aa08bfd789328c6576cd0f1fde4a3d686703bb0c247697\n",
      "Successfully built ffmpy\n",
      "Installing collected packages: pydub, ffmpy, websockets, uc-micro-py, typing-extensions, semantic-version, python-multipart, pygments, orjson, multidict, mdurl, frozenlist, async-timeout, aiofiles, yarl, markdown-it-py, linkify-it-py, httpcore, aiosignal, mdit-py-plugins, httpx, altair, aiohttp, gradio-client, gradio\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "Successfully installed aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 altair-5.0.1 async-timeout-4.0.2 ffmpy-0.3.0 frozenlist-1.4.0 gradio-3.36.1 gradio-client-0.2.9 httpcore-0.17.3 httpx-0.24.1 linkify-it-py-2.0.2 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 mdurl-0.1.2 multidict-6.0.4 orjson-3.9.2 pydub-0.25.1 pygments-2.15.1 python-multipart-0.0.6 semantic-version-2.10.0 typing-extensions-4.7.1 uc-micro-py-1.0.2 websockets-11.0.3 yarl-1.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.2.2 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.2.2 requires pyqtwebengine<5.13, which is not installed.\n",
      "tensorflow 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.7.1 which is incompatible.\n",
      "tensorflow-recommenders 0.7.3 requires tensorflow>=2.9.0; sys_platform != \"darwin\", but you have tensorflow 2.6.0 which is incompatible.\n",
      "tensorflow-intel 2.12.0 requires absl-py>=1.0.0, but you have absl-py 0.15.0 which is incompatible.\n",
      "tensorflow-intel 2.12.0 requires flatbuffers>=2.0, but you have flatbuffers 1.12 which is incompatible.\n",
      "tensorflow-intel 2.12.0 requires keras<2.13,>=2.12.0, but you have keras 2.6.0 which is incompatible.\n",
      "tensorflow-intel 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.19.5 which is incompatible.\n",
      "tensorflow-intel 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8bcf4169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing_extensions in c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages (4.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stilinski\\anaconda3\\new folder\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade typing_extensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d470dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade typing_extensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9a327c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall typing_extensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "0eefa00c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Interface.launch of Gradio Interface for: predict\n",
       "-----------------------------\n",
       "inputs:\n",
       "|-Textbox(label=\"None\")\n",
       "outputs:\n",
       "|-Textbox(label=\"None\")>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def predict(sentence):\n",
    "    load_model =TFDistilBertForSequenceClassification.from_pretrained('/sentiment_model')\n",
    "    predict_input =tokenizer.encode(sentence,\n",
    "                                   truncation =True,\n",
    "                                   padding=True,\n",
    "                                   return_tensors ='tf')\n",
    "    tf_output=load.predict(predict_input)[0]\n",
    "    tf_prediction =tf.nn.softmax(tf_output,axis=1).numpy()[0]\n",
    "    return['negative','positive'][np.argmax(tf-prediction)]\n",
    "demo =gr.Interface(fn=predict, inputs ='text',outputs='text',live=True)\n",
    "\n",
    "demo.launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "0f26769e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 2.0.4, however version 3.14.0 is available, please upgrade.\n",
      "--------\n",
      "Running locally at: http://127.0.0.1:7860/\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7860/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x23e855cadc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Flask 'gradio.networking'>, 'http://127.0.0.1:7860/', None)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-12 13:55:24,897] ERROR in app: Exception on /static/bundle.css [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask_cors\\extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\gradio\\networking.py\", line 136, in static_resource\n",
      "    return send_file(os.path.join(STATIC_PATH_LIB, path))\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\helpers.py\", line 629, in send_file\n",
      "    file = open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\stilinski\\\\anaconda3\\\\New folder\\\\lib\\\\site-packages\\\\gradio\\\\frontend\\\\static\\\\bundle.css'\n",
      "[2023-07-12 13:55:25,103] ERROR in app: Exception on /static/css/main.2b64a968.css [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask_cors\\extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\gradio\\networking.py\", line 136, in static_resource\n",
      "    return send_file(os.path.join(STATIC_PATH_LIB, path))\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\helpers.py\", line 629, in send_file\n",
      "    file = open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\stilinski\\\\anaconda3\\\\New folder\\\\lib\\\\site-packages\\\\gradio\\\\frontend\\\\static\\\\css/main.2b64a968.css'\n",
      "[2023-07-12 13:55:25,238] ERROR in app: Exception on /static/bundle.js [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask_cors\\extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\gradio\\networking.py\", line 136, in static_resource\n",
      "    return send_file(os.path.join(STATIC_PATH_LIB, path))\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\helpers.py\", line 629, in send_file\n",
      "    file = open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\stilinski\\\\anaconda3\\\\New folder\\\\lib\\\\site-packages\\\\gradio\\\\frontend\\\\static\\\\bundle.js'\n",
      "[2023-07-12 13:55:56,507] ERROR in app: Exception on /static/bundle.css [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask_cors\\extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\gradio\\networking.py\", line 136, in static_resource\n",
      "    return send_file(os.path.join(STATIC_PATH_LIB, path))\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\helpers.py\", line 629, in send_file\n",
      "    file = open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\stilinski\\\\anaconda3\\\\New folder\\\\lib\\\\site-packages\\\\gradio\\\\frontend\\\\static\\\\bundle.css'\n",
      "[2023-07-12 13:55:56,517] ERROR in app: Exception on /static/css/main.2b64a968.css [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask_cors\\extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\gradio\\networking.py\", line 136, in static_resource\n",
      "    return send_file(os.path.join(STATIC_PATH_LIB, path))\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\helpers.py\", line 629, in send_file\n",
      "    file = open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\stilinski\\\\anaconda3\\\\New folder\\\\lib\\\\site-packages\\\\gradio\\\\frontend\\\\static\\\\css/main.2b64a968.css'\n",
      "[2023-07-12 13:55:56,577] ERROR in app: Exception on /static/bundle.js [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask_cors\\extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\gradio\\networking.py\", line 136, in static_resource\n",
      "    return send_file(os.path.join(STATIC_PATH_LIB, path))\n",
      "  File \"C:\\Users\\stilinski\\anaconda3\\New folder\\lib\\site-packages\\flask\\helpers.py\", line 629, in send_file\n",
      "    file = open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\stilinski\\\\anaconda3\\\\New folder\\\\lib\\\\site-packages\\\\gradio\\\\frontend\\\\static\\\\bundle.js'\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def predict(sentence):\n",
    "    # Load your model and perform the prediction\n",
    "    # Replace this with your actual model code\n",
    "    prediction = \"This is the predicted output for: \" + sentence\n",
    "\n",
    "    return prediction\n",
    "\n",
    "# Create an input component for the sentence input\n",
    "input_text = gr.inputs.Textbox(label=\"Enter a sentence\")\n",
    "\n",
    "# Create an output component to display the prediction\n",
    "output_text = gr.outputs.Textbox(label=\"Prediction\")\n",
    "\n",
    "# Create the Gradio interface with the predict function, input, and output components\n",
    "gr.Interface(fn=predict, inputs=input_text, outputs=output_text).launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158c691d",
   "metadata": {},
   "source": [
    "In the below line of code we have the gradio implementation of the model and using google colabs we would have actually have had two columns of text and  the sentiment .Thus that  is the breakdown of our asentiment analysis using deep learning "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
